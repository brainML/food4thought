{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import vq, kmeans, whiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to stimuli (cocoids)\n",
    "all_stimulus_path = ''\n",
    "\n",
    "#path to clip embeddings, ordered by all_stimulus_path\n",
    "clip_embs_path = ''\n",
    "\n",
    "#path to resnet embeddings, ordered by all_stimulus_path\n",
    "resnet_embs_path = ''\n",
    "\n",
    "#exact coco ids used for clustering \n",
    "stim_ids_path = '/data/non_shared_food_coco_ids.npy'\n",
    "\n",
    "#base path to voxel hcp mask\n",
    "voxel_hcp_mask_path = ''\n",
    "\n",
    "#base path to food v all mask\n",
    "voxel_food_v_all_mask_path = ''\n",
    "\n",
    "#base preprocessed voxels path \n",
    "voxels_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voxels embedding\n",
    "\n",
    "subj=1\n",
    "path = voxel_hcp_mask_path.format(subj)\n",
    "voxels = np.load(path)\n",
    "indices = voxels.nonzero()\n",
    "\n",
    "path2 = voxel_food_v_all_mask_path.format(subj)\n",
    "voxels2 = np.load(path2)\n",
    "indices2 = np.where(voxels2<=0.05)\n",
    "\n",
    "indices0_set = set(indices[0].tolist())\n",
    "indices2_set = set(indices2[0].tolist())\n",
    "intersec_indices = list(indices0_set.intersection(indices2_set))\n",
    "\n",
    "voxels = np.load(voxels_path.format(subj))[:, intersec_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_embs = np.load(clip_embs_path)\n",
    "resnet_embs = np.load(resnet_embs_path)\n",
    "voxel_embs = voxels\n",
    "\n",
    "#choose which embedding\n",
    "embs = clip_embs\n",
    "all_stimulus = np.load(all_stimulus_path)\n",
    "stim_ids = np.load(stim_ids_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = ''\n",
    "dataType = 'train2017'\n",
    "dataType_val = 'val2017'\n",
    "annFile = '{}/instances_{}.json'.format(dataDir, dataType)\n",
    "annFile2 = '{}/instances_{}.json'.format(dataDir, dataType_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(annFile)\n",
    "coco2 = COCO(annFile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayCOCOImg(coco_ids, cluster=-1, download=False, output_dir = ''):\n",
    "    count = 0\n",
    "    for coco_id in coco_ids:\n",
    "        print(\"coco_ID: \", coco_id)\n",
    "        try:\n",
    "            img = coco.loadImgs(coco_id)\n",
    "            img = img[0]\n",
    "            I = io.imread(img['coco_url'])\n",
    "            \n",
    "            #download\n",
    "            if download:\n",
    "                tarDir = output_dir\n",
    "                fname = tarDir  + img['file_name']\n",
    "                urlretrieve(img['coco_url'], fname)\n",
    "            \n",
    "            plt.imshow(I); \n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        except:\n",
    "            img = coco2.loadImgs(coco_id)\n",
    "            img = img[0]\n",
    "            I = io.imread(img['coco_url'])\n",
    "            \n",
    "            #download\n",
    "            if download:\n",
    "                tarDir = output_dir\n",
    "                fname = tarDir  + img['file_name']\n",
    "                urlretrieve(img['coco_url'], fname)\n",
    "            \n",
    "            plt.imshow(I); \n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_subset = embs[stim_ids]\n",
    "stimulus_subset = all_stimulus[stim_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClusters(embs_subset, num_clusters):\n",
    "    whitened = whiten(embs_subset)\n",
    "    book = np.array((whitened[0],whitened[2]))\n",
    "    centroids = kmeans(whitened.astype(float),num_clusters)\n",
    "    \n",
    "    assignments = []\n",
    "    for i in range(len(embs_subset)):\n",
    "        dists = []\n",
    "        for centroid_i in range(len(centroids[0])):\n",
    "            curr_dist = np.linalg.norm(embs_subset[i] - centroids[0][centroid_i])\n",
    "            dists.append(curr_dist)\n",
    "        dists_np = np.asarray(dists)\n",
    "        min_centroid = np.argmin(dists_np)\n",
    "        \n",
    "        assignments.append(min_centroid)\n",
    "    \n",
    "    all_inds = []\n",
    "    all_stimuli_subset = []\n",
    "    for centroid_i in range(num_clusters):\n",
    "        curr_centroid_inds = np.where(np.asarray(assignments) == centroid_i)[0]\n",
    "        all_inds.append(curr_centroid_inds)\n",
    "        \n",
    "    return centroids, all_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, centroid_ids = getClusters(embs_subset, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopImgsInCluster(cluster_i, top_n=10):\n",
    "    inds = np.asarray(centroid_ids[cluster_i])\n",
    "    \n",
    "    centroids_tiled = np.tile(centroids[0][cluster_i], (len(inds), 1))\n",
    "    sums = np.sqrt(np.sum(np.square(embs_subset[inds] - centroids_tiled), 1))\n",
    "    top_stimuli = stimulus_subset[inds][(sums).argsort()[:top_n]]\n",
    "    \n",
    "    for stim in top_stimuli:\n",
    "        displayCOCOImg([int(stim)], cluster_i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 0\n",
    "for i in range(len(centroid_ids)):\n",
    "    num_data += len(centroid_ids[i])\n",
    "num_data\n",
    "\n",
    "same_cluster_mtx = np.zeros((num_data,num_data))\n",
    "for cluster_num in range(4):\n",
    "    for i in range(len(centroid_ids[cluster_num])):\n",
    "        for j in range(i, len(centroid_ids[cluster_num])):\n",
    "            same_cluster_mtx[centroid_ids[cluster_num][i]][centroid_ids[cluster_num][j]] = 1\n",
    "            same_cluster_mtx[centroid_ids[cluster_num][j]][centroid_ids[cluster_num][i]] = 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
